{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhenlanwang0426/.venv311/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import typing as tp\n",
    "from pathlib import Path\n",
    "from functools import partial\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "import pandas as pd\n",
    "import pyctcdecode\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import librosa\n",
    "\n",
    "import pyctcdecode\n",
    "import kenlm\n",
    "import torch\n",
    "from transformers import Wav2Vec2Processor, Wav2Vec2ProcessorWithLM, Wav2Vec2ForCTC\n",
    "from bnunicodenormalizer import Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLING_RATE = 16_000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load model, processor, decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('model/best.pth',map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = Wav2Vec2Processor.from_pretrained('model')\n",
    "vocab_dict = processor.tokenizer.get_vocab()\n",
    "sorted_vocab_dict = {k: v for k, v in sorted(vocab_dict.items(), key=lambda item: item[1])}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prepare dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BengaliSRTestDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        audio_paths: list[str],\n",
    "        sampling_rate: int\n",
    "    ):\n",
    "        self.audio_paths = audio_paths\n",
    "        self.sampling_rate = sampling_rate\n",
    "        \n",
    "    def __len__(self,):\n",
    "        return len(self.audio_paths)\n",
    "    \n",
    "    def __getitem__(self, index: int):\n",
    "        audio_path = self.audio_paths[index]\n",
    "        sr = self.sampling_rate\n",
    "        w = librosa.load(audio_path, sr=sr, mono=False)[0]\n",
    "        \n",
    "        return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000005f3362c</td>\n",
       "      <td>ও বলেছে আপনার ঠিকানা!</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00001dddd002</td>\n",
       "      <td>কোন মহান রাষ্ট্রের নাগরিক হতে চাও?</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00001e0bc131</td>\n",
       "      <td>আমি তোমার কষ্টটা বুঝছি, কিন্তু এটা সঠিক পথ না।</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000024b3d810</td>\n",
       "      <td>নাচ শেষ হওয়ার পর সকলে শরীর ধুয়ে একসঙ্গে ভোজন...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000028220ab3</td>\n",
       "      <td>হুমম, ওহ হেই, দেখো।</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019</th>\n",
       "      <td>00417912a6ee</td>\n",
       "      <td>আমাদের সঙ্গে ছিলেন এক বৃদ্ধ সাধু।</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>0041949399ee</td>\n",
       "      <td>প্রেম, মার তাকে!</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>0041a6298d5c</td>\n",
       "      <td>আমি তাকে অবাধ্য হতে প্ররোচিত করিনি।</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1022</th>\n",
       "      <td>0041a78a26ec</td>\n",
       "      <td>তিনি বর্তমানে হেভিওয়েট বিভাগে প্রতিদ্বন্দ্বিত...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1023</th>\n",
       "      <td>0041c19f4d06</td>\n",
       "      <td>ব্রাজিলের ডগলাস কস্তাও বাইরে মারলে সান্তা ক্রু...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1024 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                id                                           sentence  split\n",
       "0     000005f3362c                              ও বলেছে আপনার ঠিকানা!  train\n",
       "1     00001dddd002                 কোন মহান রাষ্ট্রের নাগরিক হতে চাও?  train\n",
       "2     00001e0bc131     আমি তোমার কষ্টটা বুঝছি, কিন্তু এটা সঠিক পথ না।  train\n",
       "3     000024b3d810  নাচ শেষ হওয়ার পর সকলে শরীর ধুয়ে একসঙ্গে ভোজন...  train\n",
       "4     000028220ab3                                হুমম, ওহ হেই, দেখো।  train\n",
       "...            ...                                                ...    ...\n",
       "1019  00417912a6ee                  আমাদের সঙ্গে ছিলেন এক বৃদ্ধ সাধু।  train\n",
       "1020  0041949399ee                                   প্রেম, মার তাকে!  train\n",
       "1021  0041a6298d5c                আমি তাকে অবাধ্য হতে প্ররোচিত করিনি।  train\n",
       "1022  0041a78a26ec  তিনি বর্তমানে হেভিওয়েট বিভাগে প্রতিদ্বন্দ্বিত...  train\n",
       "1023  0041c19f4d06  ব্রাজিলের ডগলাস কস্তাও বাইরে মারলে সান্তা ক্রু...  train\n",
       "\n",
       "[1024 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(\"data/train.csv\").iloc[:1024]\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_audio_paths = [ \"data/train_mp3s/\"+f\"{aid}.mp3\" for aid in test[\"id\"].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = BengaliSRTestDataset(\n",
    "    test_audio_paths, SAMPLING_RATE\n",
    ")\n",
    "\n",
    "collate_func = partial(\n",
    "    processor.feature_extractor,\n",
    "    return_tensors=\"pt\", sampling_rate=SAMPLING_RATE,\n",
    "    padding=True,\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=32, shuffle=False,\n",
    "    num_workers=8, collate_fn=collate_func, drop_last=False,\n",
    "    pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "if not torch.cuda.is_available():\n",
    "    device = torch.device(\"cpu\")\n",
    "else:\n",
    "    device = torch.device(\"cuda\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-03 18:56:06.618382: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-09-03 18:56:06.632117: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-09-03 18:56:06.637302: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-09-03 18:56:06.637808: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-09-03 18:56:06.659132: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-09-03 18:56:06.672804: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-09-03 18:56:06.726244: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-09-03 18:56:07.000831: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "tcmalloc: large alloc 1925120000 bytes == 0x61162000 @  0x7f5f5d761680 0x7f5f5d782824 0x7f5f5d782b8a 0x7f5e38d45e55 0x7f5e38d22f03 0x7f5e612183a9 0x7f5e60a40233 0x7f5e6114bc6b 0x7f5e612019a8 0x7f5e612024ce 0x7f5e6120296c 0x7f5e61b23728 0x7f5e61b23775 0x7f5e6135f1e5 0x7f5e60b02b1d 0x7f5e61b244c6 0x7f5e61b24547 0x7f5e6134712b 0x7f5e60af6c3d 0x7f5e61b23f85 0x7f5e61b23fef 0x7f5e6130cd8f 0x7f5e62e0cb03 0x7f5e62e0d9f7 0x7f5e61346473 0x7f5e60af9e35 0x7f5e61cd4b61 0x7f5e617a29bc 0x7f5e7837e97a 0x4ea71b 0x63425d\n",
      "tcmalloc: large alloc 1925120000 bytes == 0xd3d52000 @  0x7f5f5d761680 0x7f5f5d782824 0x7f5f5d782b8a 0x7f5e38d45e55 0x7f5e38d22f03 0x7f5e6074c0b1 0x7f5e60745af4 0x7f5e60745b40 0x7f5e60745b94 0x7f5e60e49fef 0x7f5e61980e61 0x7f5e61980ebb 0x7f5e61613717 0x7f5e619441bf 0x7f5e61653952 0x7f5e6122bfb7 0x7f5e6120278c 0x7f5e6120296c 0x7f5e61b23728 0x7f5e61b23775 0x7f5e6135f1e5 0x7f5e60b02b1d 0x7f5e61b244c6 0x7f5e61b24547 0x7f5e6134712b 0x7f5e60af6c3d 0x7f5e61b23f85 0x7f5e61b23fef 0x7f5e6130cd8f 0x7f5e62e0cb03 0x7f5e62e0d9f7\n",
      "tcmalloc: large alloc 1925120000 bytes == 0x61162000 @  0x7f5f5d761680 0x7f5f5d782824 0x7f5f5d782b8a 0x7f5e38d45e55 0x7f5e38d22f03 0x7f5e6074c0b1 0x7f5e60745af4 0x7f5e60745b40 0x7f5e60745b94 0x7f5e60e49fef 0x7f5e61980e61 0x7f5e61980ebb 0x7f5e61613717 0x7f5e619441bf 0x7f5e61653952 0x7f5e608f946b 0x7f5e60e59f25 0x7f5e61b080e5 0x7f5e617ab40a 0x7f5e607e6b33 0x7f5e60e58b0d 0x7f5e61b0a920 0x7f5e614f3306 0x7f5e60e5f20d 0x7f5e61cd4a30 0x7f5e618b3bf4 0x7f5e60f0fd41 0x7f5e619814e0 0x7f5e6198151d 0x7f5e614a53b9 0x7f5e62efa005\n",
      "tcmalloc: large alloc 1925120000 bytes == 0x146942000 @  0x7f5f5d761680 0x7f5f5d782824 0x7f5f5d782b8a 0x7f5e38d45e55 0x7f5e38d22f03 0x7f5e6074c0b1 0x7f5e60745af4 0x7f5e60745b40 0x7f5e60745b94 0x7f5e60e49fef 0x7f5e61980e61 0x7f5e61980ebb 0x7f5e61613717 0x7f5e619441bf 0x7f5e61653952 0x7f5e608f946b 0x7f5e60e59f25 0x7f5e60f0eb4e 0x7f5e619814e0 0x7f5e6198151d 0x7f5e614a53b9 0x7f5e62efa005 0x7f5e62efaad3 0x7f5e614dd945 0x7f5e60f0b983 0x7f5e61cd5cd7 0x7f5e6165901d 0x7f5e7839e407 0x4ea71b 0x63425d 0x58b1da\n",
      "tcmalloc: large alloc 1925120000 bytes == 0x61162000 @  0x7f5f5d761680 0x7f5f5d782824 0x7f5f5d782b8a 0x7f5e38d45e55 0x7f5e38d22f03 0x7f5e6074b3bc 0x7f5e60745663 0x7f5e607456ba 0x7f5e6074571f 0x7f5e6074585e 0x7f5e61978945 0x7f5e619d9142 0x7f5e607df0cd 0x7f5e607e394a 0x7f5e607e4b49 0x7f5e619ae922 0x7f5e619ae993 0x7f5e614a7b1e 0x7f5e62ee3785 0x7f5e62ee3e86 0x7f5e614eeb3f 0x7f5e783f3b5d 0x5e7cd9 0x63425d 0x58b1da 0x563e79 0x631685 0x63403a 0x58ed6d 0x635f8f 0x63671a\n",
      "tcmalloc: large alloc 1970405376 bytes == 0x64b12000 @  0x7f5f5d761680 0x7f5f5d782824 0x7f5f5d782b8a 0x7f5e38d45e55 0x7f5e38d22f03 0x7f5e612183a9 0x7f5e60a40233 0x7f5e6114bc6b 0x7f5e612019a8 0x7f5e612024ce 0x7f5e6120296c 0x7f5e61b23728 0x7f5e61b23775 0x7f5e6135f1e5 0x7f5e60b02b1d 0x7f5e61b244c6 0x7f5e61b24547 0x7f5e6134712b 0x7f5e60af6c3d 0x7f5e61b23f85 0x7f5e61b23fef 0x7f5e6130cd8f 0x7f5e62e0cb03 0x7f5e62e0d9f7 0x7f5e61346473 0x7f5e60af9e35 0x7f5e61cd4b61 0x7f5e617a29bc 0x7f5e7837e97a 0x4ea71b 0x63425d\n",
      "tcmalloc: large alloc 2189361152 bytes == 0x64b12000 @  0x7f5f5d761680 0x7f5f5d782824 0x7f5f5d782b8a 0x7f5e38d45e55 0x7f5e38d22f03 0x7f5e612183a9 0x7f5e60a40233 0x7f5e6114bc6b 0x7f5e612019a8 0x7f5e612024ce 0x7f5e6120296c 0x7f5e61b23728 0x7f5e61b23775 0x7f5e6135f1e5 0x7f5e60b02b1d 0x7f5e61b244c6 0x7f5e61b24547 0x7f5e6134712b 0x7f5e60af6c3d 0x7f5e61b23f85 0x7f5e61b23fef 0x7f5e6130cd8f 0x7f5e62e0cb03 0x7f5e62e0d9f7 0x7f5e61346473 0x7f5e60af9e35 0x7f5e61cd4b61 0x7f5e617a29bc 0x7f5e7837e97a 0x4ea71b 0x63425d\n"
     ]
    }
   ],
   "source": [
    "pred_sentence_list = []\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        x = batch[\"input_values\"]\n",
    "        y = model(x).logits\n",
    "        y = y.detach().cpu().numpy()\n",
    "        pred_sentence_list.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-03 20:04:14.356756: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Downloading builder script: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4.49k/4.49k [00:00<00:00, 18.2MB/s]\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "metric = evaluate.load(\"wer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WER(args):\n",
    "    alpha,beta = args[0],args[1]\n",
    "    decoder = pyctcdecode.build_ctcdecoder(\n",
    "    list(sorted_vocab_dict.keys()),\n",
    "    'arijitx-wav2vec2-xls-r-300m-bengali/language_model/5gram.bin',\n",
    "    alpha=alpha,beta=beta,\n",
    "    )\n",
    "\n",
    "    processor_with_lm = Wav2Vec2ProcessorWithLM(\n",
    "        feature_extractor=processor.feature_extractor,\n",
    "        tokenizer=processor.tokenizer,\n",
    "        decoder=decoder\n",
    "    )\n",
    "\n",
    "    transcriptions = []\n",
    "    for logits in pred_sentence_list:\n",
    "        for logit in logits:\n",
    "            transcriptions.append(processor_with_lm.decode(logit, beam_width=512).text)\n",
    "\n",
    "    wer = metric.compute(predictions=transcriptions, references=test.sentence.values.tolist())\n",
    "    return wer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "pool = multiprocessing.Pool(processes=36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = pool.map(WER, itertools.product(np.linspace(0.5,5,6), np.linspace(0.5,6,6)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"scores.pickle\", \"wb\") as output_file:\n",
    "    pickle.dump(scores, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
