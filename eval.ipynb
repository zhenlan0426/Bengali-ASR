{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-07-30T13:45:20.390377Z","iopub.status.busy":"2023-07-30T13:45:20.390053Z","iopub.status.idle":"2023-07-30T13:45:24.039550Z","shell.execute_reply":"2023-07-30T13:45:24.038543Z","shell.execute_reply.started":"2023-07-30T13:45:20.390351Z"},"scrolled":true,"trusted":true},"outputs":[],"source":["import jax.numpy as jnp\n","import jax\n","\n","IsTPU = False\n","batch_size = 64\n","dtype = jnp.float16\n","speech_path = '/home/zhenlan/Desktop/Projects/Bengali ASR/dlsprint/validation_files/'\n","data_path = '/home/zhenlan/Desktop/Projects/Bengali ASR/dlsprint/validation.csv'\n","\n","model_path = '/home/zhenlan/Desktop/Projects/Bengali ASR/model_all3'\n","num_workers = 8\n","output_path = ''"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-07-30T13:45:24.041752Z","iopub.status.busy":"2023-07-30T13:45:24.041393Z","iopub.status.idle":"2023-07-30T13:45:31.173641Z","shell.execute_reply":"2023-07-30T13:45:31.172145Z","shell.execute_reply.started":"2023-07-30T13:45:24.041724Z"},"trusted":true},"outputs":[],"source":["#from whisper_jax import FlaxWhisperForConditionalGeneration\n","from transformers import FlaxWhisperForConditionalGeneration\n","from functions import *\n","from functools import partial\n","import optax\n","import evaluate\n","from jax import random\n","from transformers import AutoTokenizer\n","import time\n","import warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-07-30T13:46:20.634072Z","iopub.status.busy":"2023-07-30T13:46:20.633641Z","iopub.status.idle":"2023-07-30T13:46:24.324136Z","shell.execute_reply":"2023-07-30T13:46:24.322657Z","shell.execute_reply.started":"2023-07-30T13:46:20.634037Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This means that tokens that come after special tokens will not be properly handled. We recommend you to read the related pull request available at https://github.com/huggingface/transformers/pull/24565, and set the legacy attribute accordingly.\n"]}],"source":["pad_to_multiple_of = 1\n","max_length_gen = 24\n","epochs = 1\n","verbose = 5\n","learning_rate=4e-4\n","clip = 1e-2\n","# tokenizer = WhisperTokenizer.from_pretrained(\"openai/whisper-large-v2\", language=\"bn\", task=\"transcribe\")\n","#tokenizer = AutoTokenizer.from_pretrained(\"csebuetnlp/banglat5\")\n","tokenizer = AutoTokenizer.from_pretrained(\"csebuetnlp/banglat5\")\n","tokenizer.bos_token = tokenizer.bos_token_id = None\n","feature_extractor = WhisperFeatureExtractor.from_pretrained(\"openai/whisper-large-v2\")\n","text = pd.read_csv(data_path)"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-07-30T13:46:32.166568Z","iopub.status.busy":"2023-07-30T13:46:32.165544Z","iopub.status.idle":"2023-07-30T13:46:32.174103Z","shell.execute_reply":"2023-07-30T13:46:32.172823Z","shell.execute_reply.started":"2023-07-30T13:46:32.166526Z"},"trusted":true},"outputs":[],"source":["dataset1 = AudioDataset(text,speech_path,lambda x:x.path,\\\n","                       None,orig_sr=32000, target_sr=16000)\n","train_loader = DataLoader(dataset1, batch_size=batch_size, shuffle=False, num_workers=num_workers, \\\n","                         collate_fn=partial(collate_fn,tokenizer=tokenizer,feature_extractor=feature_extractor,\\\n","                                           pad_to_multiple_of=pad_to_multiple_of,IsTrain=True,IsTPU=IsTPU,batch_size=batch_size))\n","\n","dataset2 = AudioDataset(text,speech_path,lambda x:x.path,\\\n","                       None,orig_sr=32000, target_sr=16000)\n","train_loader2 = DataLoader(dataset2, batch_size=batch_size, shuffle=False, num_workers=num_workers, \\\n","                         collate_fn=partial(collate_fn,tokenizer=tokenizer,feature_extractor=feature_extractor,\\\n","                                           pad_to_multiple_of=pad_to_multiple_of,IsTrain=False,IsTPU=IsTPU,batch_size=batch_size))\n","# dataset = AudioDataset(text.iloc[960000:],speech_path)\n","# test_loader = DataLoader(dataset, batch_size=batch_size*4, shuffle=False, num_workers=num_workers, \\\n","#                         collate_fn=partial(collate_fn,tokenizer=tokenizer,feature_extractor=feature_extractor,\\\n","#                                            pad_to_multiple_of=pad_to_multiple_of,IsTrain=True,IsTPU=IsTPU,batch_size=batch_size))"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-07-30T13:46:33.722832Z","iopub.status.busy":"2023-07-30T13:46:33.722475Z","iopub.status.idle":"2023-07-30T13:46:51.296694Z","shell.execute_reply":"2023-07-30T13:46:51.295376Z","shell.execute_reply.started":"2023-07-30T13:46:33.722802Z"},"trusted":true},"outputs":[],"source":["# load the processor and model\n","model, params = FlaxWhisperForConditionalGeneration.from_pretrained(\n","    model_path, dtype=dtype, _do_init=False)\n","# params = model.params\n","\n","model.config.forced_decoder_ids = None\n","model.config.bos_token_id = None\n","model.config.suppress_tokens = None\n","model.config.decoder_start_token_id = None\n","model.generation_config.decoder_start_token_id = [50258, 50302, 50359, 50363]# '<|startoftranscript|><|bn|><|transcribe|><|notimestamps|>\n","model.generation_config.forced_decoder_ids = None\n","\"\"\"A list of pairs of integers which indicates a mapping from generation indices to token indices \n","that will be forced before sampling. For example, [[0, 123]] means the first generated token \n","will always be a token of index 123.\"\"\"\n","model.generation_config.suppress_tokens = None\n","model.generation_config.begin_suppress_tokens = None\n","model.generation_config.bos_token_id = None"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-07-30T13:46:54.179409Z","iopub.status.busy":"2023-07-30T13:46:54.179100Z","iopub.status.idle":"2023-07-30T13:46:54.193733Z","shell.execute_reply":"2023-07-30T13:46:54.192803Z","shell.execute_reply.started":"2023-07-30T13:46:54.179384Z"},"trusted":true},"outputs":[],"source":["# @partial(jax.pmap,axis_name='data',in_axes=(None,None,0,0,0,None),out_axes=(None,None,None))\n","# def train_one_step_embed(embedding,params,audio,input_ids,attention_mask,opt_states):\n","#     def loss_fn(embedding,params,audio,input_ids,attention_mask):\n","#         params['model']['decoder']['embed_tokens']['embedding'] = embedding\n","#         out = model(audio,input_ids,decoder_attention_masjn_mask):\n","#         params['model']['decoder']['embed_tokens']['embedding'] = embedding\n","#         out = model(audio,input_ids,decoder_attention_mask=attention_mask,params=params,train=True).logits # (B, L, d)\n","#         return jnp.mean(optax.softmax_cross_entropy_with_integer_labels(out[:,3:-1], input_ids[:,4:])*attention_mask[:,4:])\n","#     grad_fn = jax.value_and_grad(loss_fn,has_aux=False)\n","#     l,grads = grad_fn(embedding,params,audio,input_ids,attention_mask)\n","#     updates, opt_states = opt.update(grads, opt_states,params=embedding)\n","#     embedding = optax.apply_updates(embedding, updates)\n","#     return embedding,opt_states,l\n","\n","# @jax.jit\n","def eval_one_step(params,audio,input_ids,attention_mask):\n","    out = model(audio,input_ids,decoder_attention_mask=attention_mask,params=params,train=False).logits # (B, L, d)\n","    return jnp.mean(optax.softmax_cross_entropy_with_integer_labels(out[:,3:-1], input_ids[:,4:])*attention_mask[:,4:])\n","\n","#@jax.jit\n","# def train_one_step(params,audio,input_ids,attention_mask,opt_states):\n","#     def loss_fn(params,audio,input_ids,attention_mask):\n","#         out = model(audio,input_ids,decoder_attention_mask=attention_mask,params=params,train=True).logits # (B, L, d)\n","#         return jnp.mean(optax.softmax_cross_entropy_with_integer_labels(out[:,3:-1], input_ids[:,4:])*attention_mask[:,4:])\n","#     grad_fn = jax.value_and_grad(loss_fn,has_aux=False)\n","#     l,grads = grad_fn(params,audio,input_ids,attention_mask)\n","#     updates, opt_states = opt.update(grads, opt_states,params=params)\n","#     params = optax.apply_updates(params, updates)\n","#     return params,opt_states,l\n","\n","# @jax.jit\n","def generate(audio):\n","    return model.generate(audio,params=params,max_length=max_length_gen, num_beams=1, do_sample=False).sequences\n","\n","metric = evaluate.load(\"wer\")\n","def metric_one_step(audio,txt):\n","    generated_ids = generate(audio)\n","    transcriptions = tokenizer.batch_decode(generated_ids.tolist(), skip_special_tokens=True)\n","    wer = metric.compute(predictions=transcriptions, references=txt)\n","    return wer\n","\n","# def batch_generate(loader):\n","#     pass\n","#     #transcriptions = [txt + \"|\" for txt in transcriptions]"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0.4285888671875\n","CPU times: user 48min 35s, sys: 22min 36s, total: 1h 11min 11s\n","Wall time: 7min 28s\n"]}],"source":["%%time\n","# # model_all3\n","test_loss = 0\n","for j,(audio,input_ids,attention_mask) in enumerate(train_loader):\n","    #audio,input_ids,attention_mask = jnp.array(audio,dtype=dtype),jnp.array(input_ids),jnp.array(attention_mask)\n","    l = eval_one_step(params,audio,input_ids,attention_mask)\n","    test_loss += l.item()\n","    if j>20:\n","        break\n","test_loss /= (j+1)\n","print(test_loss)"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0.3622065277408587\n","CPU times: user 1h 8min 18s, sys: 24min 38s, total: 1h 32min 57s\n","Wall time: 12min 31s\n"]}],"source":["%%time\n","# model_all3\n","test_loss = 0\n","for j,(audio,txt) in enumerate(train_loader2):\n","    #audio,input_ids,attention_mask = jnp.array(audio,dtype=dtype),jnp.array(input_ids),jnp.array(attention_mask)\n","    l = metric_one_step(audio,txt)\n","    test_loss += l\n","    if j>20:\n","        break\n","test_loss /= (j+1)\n","print(test_loss)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"}},"nbformat":4,"nbformat_minor":4}
