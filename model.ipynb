{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install art --target=/kaggle/working/mysitepackages","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import jax.numpy as jnp\nimport jax\nif jax.device_count()>1:\n    IsTPU = True\n    dtype = jnp.bfloat16\n    num_workers = 16\n    batch_size = 16 * 8\n#     try:\n#         import transformers\n#         speech_path = 'bengaliai-speech/train_mp3s/'\n#         data_path = 'bengaliai-speech/train.csv'\n#         output_path = ''\n#     except:\n#         !pip install librosa --quiet --target=/kaggle/working/mysitepackages\n#         !pip install git+https://github.com/zhenlan0426/transformers --quiet --target=/kaggle/working/mysitepackages\n#         !pip install evaluate --quiet --target=/kaggle/working/mysitepackages\n#         !pip install sentencepiece --quiet --target=/kaggle/working/mysitepackages\n#         !pip install jiwer --quiet --target=/kaggle/working/mysitepackages\n#         !pip install audiomentations --quiet --target=/kaggle/working/mysitepackages\n    speech_path = '/kaggle/input/bengaliai-speech/train_mp3s/'\n    data_path = '/kaggle/input/bengaliai-speech/train.csv'\n    output_path = '/kaggle/working/'\n    background = '/kaggle/input/esc-50/audio'\n    model_path = '/kaggle/input/model/model_embed'\nelse:\n    IsTPU = False\n    batch_size = 32\n    dtype = jnp.float16\n    speech_path = 'data/train_mp3s/'\n    data_path = 'data/train.csv'\n    num_workers = 0\n    output_path = ''\n    background = \"/home/zhenlan/Desktop/Projects/Bengali ASR/ESC-50-master/audio\"","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-07-31T13:14:20.292703Z","iopub.execute_input":"2023-07-31T13:14:20.293237Z","iopub.status.idle":"2023-07-31T13:14:20.335570Z","shell.execute_reply.started":"2023-07-31T13:14:20.293200Z","shell.execute_reply":"2023-07-31T13:14:20.334333Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# from whisper_jax import FlaxWhisperForConditionalGeneration\nimport sys\nsys.path.append('/kaggle/working/mysitepackages')\nfrom transformers import FlaxWhisperForConditionalGeneration\nfrom functions import *\nfrom functools import partial\nimport optax\nimport evaluate\nfrom jax import random\nfrom transformers import AutoTokenizer\nimport time\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2023-07-31T13:14:34.724609Z","iopub.execute_input":"2023-07-31T13:14:34.724992Z","iopub.status.idle":"2023-07-31T13:14:48.477702Z","shell.execute_reply.started":"2023-07-31T13:14:34.724961Z","shell.execute_reply":"2023-07-31T13:14:48.476385Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"code","source":"pad_to_multiple_of = 4\nmax_length_gen = 48\nepochs = 1\nverbose = 5\n\n\n# tokenizer = WhisperTokenizer.from_pretrained(\"openai/whisper-large-v2\", language=\"bn\", task=\"transcribe\")\ntokenizer = AutoTokenizer.from_pretrained(\"csebuetnlp/banglat5\")\ntokenizer.bos_token = tokenizer.bos_token_id = None\nfeature_extractor = WhisperFeatureExtractor.from_pretrained(\"openai/whisper-large-v2\")\ntext = pd.read_csv(data_path)","metadata":{"execution":{"iopub.status.busy":"2023-07-31T13:16:10.658128Z","iopub.execute_input":"2023-07-31T13:16:10.658526Z","iopub.status.idle":"2023-07-31T13:16:17.394091Z","shell.execute_reply.started":"2023-07-31T13:16:10.658494Z","shell.execute_reply":"2023-07-31T13:16:17.392454Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"\"https://github.com/karoldvl/ESC-50/archive/master.zip\"\nfrom audiomentations import (\n    AddBackgroundNoise,\n    AddGaussianNoise,\n    Compose,\n    Gain,\n    GainTransition,\n    OneOf,\n    PitchShift,\n    PolarityInversion,\n    TimeStretch,\n    )\n\n# define augmentation\naugmentation = Compose(\n    [\n        TimeStretch(min_rate=0.9, max_rate=1.1, p=0.5, leave_length_unchanged=False),\n        Gain(min_gain_db=-6, max_gain_db=6, p=0.5),\n        GainTransition(min_gain_db=-6, max_gain_db=6),\n        PitchShift(min_semitones=-4, max_semitones=4, p=0.5),\n        AddBackgroundNoise(sounds_path=background, min_snr_in_db=1.0, max_snr_in_db=5.0, noise_transform=PolarityInversion(), p=1.0),\n        AddGaussianNoise(min_amplitude=0.005, max_amplitude=0.015, p=0.5),\n    ]\n)\n","metadata":{"execution":{"iopub.status.busy":"2023-07-31T13:16:23.516152Z","iopub.execute_input":"2023-07-31T13:16:23.516636Z","iopub.status.idle":"2023-07-31T13:16:24.602180Z","shell.execute_reply.started":"2023-07-31T13:16:23.516596Z","shell.execute_reply":"2023-07-31T13:16:24.600575Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"dataset = AudioDataset(text,speech_path,augmentation)\ntrain_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, \\\n                        collate_fn=partial(collate_fn,tokenizer=tokenizer,feature_extractor=feature_extractor,\\\n                                           pad_to_multiple_of=pad_to_multiple_of,IsTrain=True,IsTPU=IsTPU,batch_size=batch_size))\n\n# dataset = AudioDataset(text.iloc[950000:],speech_path)\n# test_loader = DataLoader(dataset, batch_size=batch_size*4, shuffle=False, num_workers=num_workers, \\\n#                         collate_fn=partial(collate_fn,tokenizer=tokenizer,feature_extractor=feature_extractor,pad_to_multiple_of=pad_to_multiple_of,IsTrain=True))","metadata":{"execution":{"iopub.status.busy":"2023-07-31T13:16:37.317708Z","iopub.execute_input":"2023-07-31T13:16:37.318181Z","iopub.status.idle":"2023-07-31T13:16:37.325755Z","shell.execute_reply.started":"2023-07-31T13:16:37.318145Z","shell.execute_reply":"2023-07-31T13:16:37.324814Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# audio,input_ids,attention_mask = next(iter(train_loader))\n# audio,input_ids,attention_mask = jnp.array(audio,dtype=dtype),jnp.array(input_ids),jnp.array(attention_mask)","metadata":{"execution":{"iopub.status.busy":"2023-07-30T13:46:32.865035Z","iopub.execute_input":"2023-07-30T13:46:32.865948Z","iopub.status.idle":"2023-07-30T13:46:32.870110Z","shell.execute_reply.started":"2023-07-30T13:46:32.865911Z","shell.execute_reply":"2023-07-30T13:46:32.869052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load the processor and model\nmodel, params = FlaxWhisperForConditionalGeneration.from_pretrained(\n    model_path, dtype=dtype, _do_init=False,)\nmodel.config.forced_decoder_ids = None\nmodel.config.bos_token_id = None\nmodel.config.suppress_tokens = None\nmodel.config.decoder_start_token_id = None\nmodel.generation_config.decoder_start_token_id = [50258, 50302, 50359, 50363]# '<|startoftranscript|><|bn|><|transcribe|><|notimestamps|>\nmodel.generation_config.forced_decoder_ids = None\n\"\"\"A list of pairs of integers which indicates a mapping from generation indices to token indices \nthat will be forced before sampling. For example, [[0, 123]] means the first generated token \nwill always be a token of index 123.\"\"\"\nmodel.generation_config.suppress_tokens = None\nmodel.generation_config.begin_suppress_tokens = None\nmodel.generation_config.bos_token_id = None","metadata":{"execution":{"iopub.status.busy":"2023-07-31T13:19:28.061550Z","iopub.execute_input":"2023-07-31T13:19:28.061936Z","iopub.status.idle":"2023-07-31T13:21:01.880799Z","shell.execute_reply.started":"2023-07-31T13:19:28.061905Z","shell.execute_reply":"2023-07-31T13:21:01.878231Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# # ensure std of init is the same\n# std_ = params['model']['decoder']['embed_tokens']['embedding'].std().item()\n# # reset the embedding params\n# params['model']['decoder']['embed_tokens']['embedding'] = params['model']['decoder']['embed_tokens']['embedding'].at[:tokenizer.vocab_size]\\\n#                                                                 .set(random.normal(random.PRNGKey(7),(tokenizer.vocab_size,model.config.d_model)) * std_)\n# embedding = params['model']['decoder']['embed_tokens']['embedding']","metadata":{"execution":{"iopub.status.busy":"2023-07-30T13:46:51.298668Z","iopub.execute_input":"2023-07-30T13:46:51.299179Z","iopub.status.idle":"2023-07-30T13:46:54.119403Z","shell.execute_reply.started":"2023-07-30T13:46:51.299147Z","shell.execute_reply":"2023-07-30T13:46:54.118079Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"opt = optax.adamw(learning_rate=3e-4,\n                  b1=0.9,\n                  b2=0.98,\n                  eps=1e-6,\n                  weight_decay=1e-1,)#1e-1\nopt = optax.chain(optax.clip_by_global_norm(1e-1),opt)\n#opt_states = opt.init(embedding)\nopt_states = opt.init(params)","metadata":{"execution":{"iopub.status.busy":"2023-07-30T13:46:54.120803Z","iopub.execute_input":"2023-07-30T13:46:54.121138Z","iopub.status.idle":"2023-07-30T13:46:54.171218Z","shell.execute_reply.started":"2023-07-30T13:46:54.121110Z","shell.execute_reply":"2023-07-30T13:46:54.170197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Generation\n# https://huggingface.co/transformers/v4.1.1/_modules/transformers/generation_logits_process.html\n# https://huggingface.co/docs/transformers.js/api/utils/generation#module_utils/\n# LogitsProcessor (input_ids: LongTensorscores with shape (batch, length), Score: FloatTensor ) → NewScore: FloatTensor with shape (batch_size, config.vocab_size)","metadata":{"execution":{"iopub.status.busy":"2023-07-30T13:46:54.173261Z","iopub.execute_input":"2023-07-30T13:46:54.173845Z","iopub.status.idle":"2023-07-30T13:46:54.177984Z","shell.execute_reply.started":"2023-07-30T13:46:54.173816Z","shell.execute_reply":"2023-07-30T13:46:54.176992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# @partial(jax.pmap,axis_name='data',in_axes=(None,None,0,0,0,None),out_axes=(None,None,None))\n# def train_one_step_embed(embedding,params,audio,input_ids,attention_mask,opt_states):\n#     def loss_fn(embedding,params,audio,input_ids,attention_mask):\n#         params['model']['decoder']['embed_tokens']['embedding'] = embedding\n#         out = model(audio,input_ids,decoder_attention_mask=attention_mask,params=params,train=True).logits # (B, L, d)\n#         return jnp.mean(optax.softmax_cross_entropy_with_integer_labels(out[:,3:-1], input_ids[:,4:])*attention_mask[:,4:])\n#     grad_fn = jax.value_and_grad(loss_fn,has_aux=False)\n#     out = grad_fn(embedding,params,audio,input_ids,attention_mask)\n#     l,grads = jax.lax.pmean(out,'data')\n#     updates, opt_states = opt.update(grads, opt_states,params=embedding)\n#     embedding = optax.apply_updates(embedding, updates)\n#     return embedding,opt_states,l\n\n@partial(jax.pmap,axis_name='data',in_axes=(None,0,0,0,None),out_axes=(None,None,None))\ndef train_one_step(params,audio,input_ids,attention_mask,opt_states):\n    def loss_fn(params,audio,input_ids,attention_mask):\n        out = model(audio,input_ids,decoder_attention_mask=attention_mask,params=params,train=True).logits # (B, L, d)\n        return jnp.mean(optax.softmax_cross_entropy_with_integer_labels(out[:,3:-1], input_ids[:,4:])*attention_mask[:,4:])\n    grad_fn = jax.value_and_grad(loss_fn,has_aux=False)\n    out = grad_fn(params,audio,input_ids,attention_mask)\n    l,grads = jax.lax.pmean(out,'data')\n    updates, opt_states = opt.update(grads, opt_states,params=params)\n    params = optax.apply_updates(params, updates)\n    return params,opt_states,l\n\n# @jax.jit\n# def train_one_step(params,audio,input_ids,attention_mask,opt_states):\n#     def loss_fn(params,audio,input_ids,attention_mask):\n#         out = model(audio,input_ids,decoder_attention_mask=attention_mask,params=params,train=True).logits # (B, L, d)\n#         return jnp.mean(optax.softmax_cross_entropy_with_integer_labels(out[:,3:-1], input_ids[:,4:])*attention_mask[:,4:])\n#     grad_fn = jax.value_and_grad(loss_fn,has_aux=False)\n#     l,grads = grad_fn(params,audio,input_ids,attention_mask)\n#     updates, opt_states = opt.update(grads, opt_states,params=params)\n#     params = optax.apply_updates(params, updates)\n#     return params,opt_states,l\n\n# @jax.jit\n# def train_one_step_embed(embedding,params,audio,input_ids,attention_mask,opt_states):\n#     def loss_fn(embedding,params,audio,input_ids,attention_mask):\n#         params['model']['decoder']['embed_tokens']['embedding'] = embedding\n#         out = model(audio,input_ids,decoder_attention_mask=attention_mask,params=params,train=True).logits # (B, L, d)\n#         return jnp.mean(optax.softmax_cross_entropy_with_integer_labels(out[:,3:-1], input_ids[:,4:])*attention_mask[:,4:])\n#     grad_fn = jax.value_and_grad(loss_fn,has_aux=False)\n#     l,grads = grad_fn(embedding,params,audio,input_ids,attention_mask)\n#     updates, opt_states = opt.update(grads, opt_states,params=embedding)\n#     embedding = optax.apply_updates(embedding, updates)\n#     return embedding,opt_states,l\n\n# @jax.jit\n# def eval_one_step(params,audio,input_ids,attention_mask):\n#     out = model(audio,input_ids,decoder_attention_mask=attention_mask,params=params,train=False).logits # (B, L, d)\n#     return jnp.mean(optax.softmax_cross_entropy_with_integer_labels(out[:,3:-1], input_ids[:,4:])*attention_mask[:,4:])\n\n\n# @jax.jit\n# def generate(params,audio):\n#     return model.generate(audio,params=params,max_length=max_length_gen)\n\n# metric = evaluate.load(\"wer\")\n# def metric_one_step(params,audio,txt):\n#     generated_ids = model.generate(audio,params=params,max_length=max_length_gen, num_beams=1, do_sample=False).sequences\n#     transcriptions = tokenizer.batch_decode(generated_ids.tolist(), skip_special_tokens=True)\n#     wer = metric.compute(predictions=transcriptions, references=txt)\n#     return wer\n\n# def batch_generate(loader):\n#     pass\n#     #transcriptions = [txt + \"|\" for txt in transcriptions]","metadata":{"execution":{"iopub.status.busy":"2023-07-30T13:46:54.179100Z","iopub.execute_input":"2023-07-30T13:46:54.179409Z","iopub.status.idle":"2023-07-30T13:46:54.193733Z","shell.execute_reply.started":"2023-07-30T13:46:54.179384Z","shell.execute_reply":"2023-07-30T13:46:54.192803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"start = time.time()\nfor i in range(epochs):\n    # train\n    train_loss = 0\n    for j,(audio,input_ids,attention_mask) in enumerate(train_loader):\n        audio,input_ids,attention_mask = jnp.array(audio,dtype=dtype),jnp.array(input_ids),jnp.array(attention_mask)\n#         embedding,opt_states,l = train_one_step_embed(embedding,params,audio,input_ids,attention_mask,opt_states)\n        params,opt_states,l = train_one_step(params,audio,input_ids,attention_mask,opt_states)\n        train_loss += l.item()\n        #print(f\"iterations:{j}, loss: {l.item():.3f}\")\n        if j>0 and j%verbose == 0:\n            train_loss /= verbose\n            print(f\"iterations:{j}, loss: {train_loss:.3f}\")\n            train_loss = 0\n            if (time.time() - start)/60/60 > 8: # 4 hours\n                model.save_pretrained(output_path+'model_all',params)\n                break\n        # # eval\n        # if j%verbose == 0:\n        #     train_loss /= verbose    \n        #     eval_metric = 0\n        #     params['model']['decoder']['embed_tokens']['embedding'] = embedding\n        #     for k,(audio,input_ids,attention_mask) in enumerate(test_loader):\n        #         audio,input_ids,attention_mask = jnp.array(audio,dtype=dtype),jnp.array(input_ids),jnp.array(attention_mask)\n        #         eval_l = eval_one_step(params,audio,input_ids,attention_mask)\n        #         eval_metric += eval_l.item()\n            \n        #     eval_metric /= k\n        #     print(f\"iterations:{j}, loss: {train_loss:.3f}, wer: {eval_metric:.3f}\")\n        #     train_loss = 0","metadata":{"execution":{"iopub.status.busy":"2023-07-30T13:46:54.194863Z","iopub.execute_input":"2023-07-30T13:46:54.195211Z","iopub.status.idle":"2023-07-30T14:19:07.371378Z","shell.execute_reply.started":"2023-07-30T13:46:54.195182Z","shell.execute_reply":"2023-07-30T14:19:07.369896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import shutil\n# shutil.rmtree('/kaggle/working/model_embed20')\n\n# from IPython.display import FileLink\n# !cd model_embed20/\n# FileLink(r'model_embed20/flax_model.msgpack')\n\n# shutil.rmtree('/kaggle/working/model_embed')\n\n# model.save_pretrained(output_path+f'model_embed',params)","metadata":{"execution":{"iopub.status.busy":"2023-07-30T14:35:29.410241Z","iopub.execute_input":"2023-07-30T14:35:29.410687Z","iopub.status.idle":"2023-07-30T14:35:51.444813Z","shell.execute_reply.started":"2023-07-30T14:35:29.410654Z","shell.execute_reply":"2023-07-30T14:35:51.443230Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}